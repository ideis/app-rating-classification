{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190649\n         Date  AppName  Language  Version  Title  Review  Reviews\nRating                                                           \n1       46520    46520     46520    46520  46520   46520    46520\n2       27071    27071     27071    27071  27071   27071    27071\n3       32499    32499     32499    32499  32499   32499    32499\n4       33600    33600     33600    33600  33600   33600    33600\n5       50959    50959     50959    50959  50959   50959    50959\n"
     ]
    }
   ],
   "source": [
    "# data wrangling\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset = pd.read_csv(\"app_review_rating_train.csv\")\n",
    "\n",
    "dataset[\"Reviews\"] = dataset[\"Title\"] + \" \" + dataset[\"Review\"]\n",
    "dataset = dataset.dropna()\n",
    "\n",
    "# oversampling\n",
    "df = dataset.loc[dataset['Rating'] == 1]\n",
    "df = pd.concat([df]*3)\n",
    "dataset = dataset.append(df)\n",
    "\n",
    "df = dataset.loc[dataset['Rating'] == 2]\n",
    "df = pd.concat([df]*5)\n",
    "dataset = dataset.append(df)\n",
    "\n",
    "df = dataset.loc[dataset['Rating'] == 3]\n",
    "df = pd.concat([df]*4)\n",
    "dataset = dataset.append(df)\n",
    "\n",
    "df = dataset.loc[dataset['Rating'] == 4]\n",
    "df = pd.concat([df]*2)\n",
    "dataset = dataset.append(df)\n",
    "\n",
    "print(dataset.groupby([\"Rating\"]).count())\n",
    "train_reviews, test_reviews, train_rating, test_rating = train_test_split(dataset[\"Reviews\"], dataset[\"Rating\"],\n",
    "                                                                          stratify=dataset[\"Rating\"],\n",
    "                                                                          test_size=0.33,\n",
    "                                                                          random_state=42)\n",
    "\n",
    "train_reviews = np.array(train_reviews)\n",
    "train_rating = np.array(train_rating)\n",
    "test_reviews = np.array(test_reviews)\n",
    "test_rating = np.array(test_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normalization\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "stopwords_list = nltk.corpus.stopwords.words('russian')\n",
    "\n",
    "\n",
    "def tokenize_text(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tokens = [token.strip() for token in tokens]\n",
    "    return tokens\n",
    "\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    tokens = tokenize_text(text)\n",
    "    filtered_tokens = [token for token in tokens if token not in stopwords_list]\n",
    "    filtered_text = ' '.join(filtered_tokens)\n",
    "    return filtered_text\n",
    "\n",
    "\n",
    "def normalize_corpus(corpus):\n",
    "    normalized_corpus = []\n",
    "    \n",
    "    for index, text in enumerate(corpus):\n",
    "        text = text.lower()\n",
    "        emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text.lower())\n",
    "        text = re.sub('[\\W]+', ' ', text.lower()) \\\n",
    "            + ' '.join(emoticons).replace('-', '')\n",
    "        text = remove_stopwords(text)\n",
    "        normalized_corpus.append(text)\n",
    "\n",
    "    return normalized_corpus\n",
    "\n",
    "\n",
    "norm_train_reviews = normalize_corpus(train_reviews)\n",
    "norm_test_reviews = normalize_corpus(test_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature extraction\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "\n",
    "def build_feature_matrix(documents, feature_type='frequency',\n",
    "                         ngram_range=(1, 1), min_df=0.0, max_df=1.0):\n",
    "\n",
    "    feature_type = feature_type.lower().strip()  \n",
    "    \n",
    "    if feature_type == 'binary':\n",
    "        vectorizer = CountVectorizer(binary=True, min_df=min_df,\n",
    "                                     max_df=max_df, ngram_range=ngram_range)\n",
    "    elif feature_type == 'frequency':\n",
    "        vectorizer = CountVectorizer(binary=False, min_df=min_df,\n",
    "                                     max_df=max_df, ngram_range=ngram_range)\n",
    "    elif feature_type == 'tfidf':\n",
    "        vectorizer = TfidfVectorizer(min_df=min_df, max_df=max_df, \n",
    "                                     ngram_range=ngram_range)\n",
    "    else:\n",
    "        raise Exception(\"Wrong feature type entered. Possible values: 'binary', 'frequency', 'tfidf'\")\n",
    "\n",
    "    feature_matrix = vectorizer.fit_transform(documents).astype(float)\n",
    "    \n",
    "    return vectorizer, feature_matrix\n",
    "\n",
    "\n",
    "vectorizer, train_features = build_feature_matrix(documents=norm_train_reviews,\n",
    "                                                  feature_type='frequency',\n",
    "                                                  ngram_range=(1, 2), \n",
    "                                                  min_df=0.0, max_df=1.0)   \n",
    "\n",
    "norm_test_reviews = normalize_corpus(test_reviews)\n",
    "test_features = vectorizer.transform(norm_test_reviews)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.linear_model.logistic.LogisticRegression'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9206945783\n\n\n<class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ideis/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ideis/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ideis/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.897270901145\n\n\n<class 'sklearn.naive_bayes.MultinomialNB'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.849953844406\n\n\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ideis/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n          intercept_scaling=1, max_iter=100, multi_class='multinomial',\n          n_jobs=1, penalty='l2', random_state=42, solver='newton-cg',\n          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model training\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# best model selection and hyperparameters optimization\n",
    "\n",
    "for clf in [LogisticRegression, SGDClassifier, MultinomialNB]:\n",
    "    print(clf)\n",
    "    print(cross_val_score(clf(), train_features, train_rating).mean())\n",
    "    print(\"\\n\")\n",
    "    \n",
    "nb = MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
    "nb.fit(train_features, train_rating)\n",
    "\n",
    "sgd = SGDClassifier(loss='log', penalty='l2')\n",
    "sgd.fit(train_features, train_rating)\n",
    "\n",
    "lg = LogisticRegression(solver='newton-cg',\n",
    "                        multi_class='multinomial',\n",
    "                        C=1,\n",
    "                        penalty='l2',\n",
    "                        max_iter=100,\n",
    "                        random_state=42)\n",
    "lg.fit(train_features, train_rating)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\nPrecision: 0.87\nRecall: 0.87\nF1 Score: 0.87\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n\n          1       0.85      0.95      0.89     15352\n          2       0.95      0.90      0.92      8933\n          3       0.91      0.88      0.90     10725\n          4       0.87      0.71      0.78     11088\n          5       0.84      0.90      0.87     16817\n\navg / total       0.88      0.87      0.87     62915\n\nSGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n       learning_rate='optimal', loss='log', max_iter=None, n_iter=None,\n       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n       shuffle=True, tol=None, verbose=0, warm_start=False)\nPrecision: 0.86\nRecall: 0.86\nF1 Score: 0.86\n             precision    recall  f1-score   support\n\n          1       0.83      0.94      0.88     15352\n          2       0.96      0.87      0.91      8933\n          3       0.92      0.86      0.89     10725\n          4       0.86      0.66      0.75     11088\n          5       0.82      0.92      0.86     16817\n\navg / total       0.87      0.86      0.86     62915\n\nLogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n          intercept_scaling=1, max_iter=100, multi_class='multinomial',\n          n_jobs=1, penalty='l2', random_state=42, solver='newton-cg',\n          tol=0.0001, verbose=0, warm_start=False)\nPrecision: 0.95\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.95\nF1 Score: 0.95\n             precision    recall  f1-score   support\n\n          1       0.96      0.98      0.97     15352\n          2       0.98      0.98      0.98      8933\n          3       0.97      0.98      0.97     10725\n          4       0.91      0.89      0.90     11088\n          5       0.92      0.91      0.92     16817\n\navg / total       0.95      0.95      0.95     62915\n\n"
     ]
    }
   ],
   "source": [
    "# model evaluation and metrics\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "def display_evaluation_metrics(true_labels, predicted_labels):\n",
    "    \n",
    "    print('Precision:', np.round(\n",
    "                        metrics.precision_score(true_labels, \n",
    "                                               predicted_labels,\n",
    "                                               average='micro'),\n",
    "                        2))\n",
    "    print('Recall:', np.round(\n",
    "                        metrics.recall_score(true_labels, \n",
    "                                               predicted_labels,\n",
    "                                               average='micro'),\n",
    "                        2))\n",
    "    print('F1 Score:', np.round(\n",
    "                        metrics.f1_score(true_labels, \n",
    "                                               predicted_labels,\n",
    "                                               average='micro'),\n",
    "                        2))\n",
    "               \n",
    "                        \n",
    "def display_classification_report(true_labels, predicted_labels, classes=[1,2,3,4,5]):\n",
    "\n",
    "    report = metrics.classification_report(y_true=true_labels, \n",
    "                                           y_pred=predicted_labels, \n",
    "                                           labels=classes) \n",
    "    print(report)\n",
    "    \n",
    "\n",
    "def display_model_quality(model, test_features, test_rating):\n",
    "    predicted_sentiments = model.predict(test_features)\n",
    "    \n",
    "    print(model)\n",
    "    display_evaluation_metrics(true_labels=test_rating,\n",
    "                               predicted_labels=predicted_sentiments)\n",
    "    \n",
    "    display_classification_report(true_labels=test_rating,\n",
    "                                  predicted_labels=predicted_sentiments,\n",
    "                                  classes=[1,2,3,4,5]) \n",
    "\n",
    "\n",
    "display_model_quality(nb, test_features, test_rating)    \n",
    "display_model_quality(sgd, test_features, test_rating)\n",
    "display_model_quality(lg, test_features, test_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5    16635\n1     5381\n4     1718\n3     1045\n2      311\nName: Rating, dtype: int64\n    Index        Date                 AppName Language Version  \\\n0       0  2016-09-22         Сбербанк Онлайн       ru   7.3.1   \n1       1  2016-03-11         Сбербанк Онлайн       ru   7.0.3   \n2       2  2015-02-14         Сбербанк Онлайн       ru   5.3.0   \n3       3  2017-02-18         Сбербанк Онлайн       ru   8.0.0   \n4       4  2014-05-07         Сбербанк Онлайн       ru   4.1.3   \n5       5  2016-09-20         Сбербанк Онлайн       ru   7.3.1   \n6       6  2016-02-17         Сбербанк Онлайн       ru   7.0.2   \n7       7  2017-10-24  Сбербанк Бизнес Онлайн       ru  2.12.1   \n8       8  2016-06-17         Сбербанк Онлайн       ru   7.2.0   \n9       9  2013-02-20         Сбербанк Онлайн       ru     3.0   \n10     10  2014-04-22         Сбербанк Онлайн       ru   4.1.1   \n11     11  2017-01-28         Сбербанк Онлайн       ru   7.4.4   \n12     12  2014-09-07         Сбербанк Онлайн       ru   5.1.0   \n14     14  2014-05-11         Сбербанк Онлайн       ru   4.1.3   \n15     15  2013-10-22         Сбербанк Онлайн       ru   4.0.2   \n16     16  2017-07-06         Сбербанк Онлайн       ru   8.1.0   \n17     17  2013-07-22         Сбербанк Онлайн       ru     4.0   \n18     18  2017-02-20         Сбербанк Онлайн       ru   8.0.0   \n19     19  2015-05-09         Сбербанк Онлайн       ru   5.3.1   \n20     20  2016-11-03         Сбербанк Онлайн       ru   7.4.2   \n21     21  2013-12-10         Сбербанк Онлайн       ru     4.1   \n22     22  2014-10-01         Сбербанк Онлайн       ru   5.1.2   \n23     23  2013-08-13         Сбербанк Онлайн       ru     4.0   \n24     24  2016-07-26         Сбербанк Онлайн       ru   7.3.0   \n25     25  2013-11-06         Сбербанк Онлайн       ru   4.0.2   \n26     26  2014-10-22         Сбербанк Онлайн       ru   5.2.0   \n27     27  2014-04-26         Сбербанк Онлайн       ru   4.1.1   \n28     28  2016-10-03         Сбербанк Онлайн       ru   7.3.1   \n29     29  2017-03-25         Сбербанк Онлайн       ru   8.0.2   \n30     30  2015-08-03         Сбербанк Онлайн       ru   5.3.1   \n\n                               Title  \\\n0                              Норм)   \n1                                гуд   \n2                         Благо дарю   \n3       Последняя обнова пздц кривая   \n4                     Что случилось?   \n5                                !!!   \n6                                ???   \n7                       Уведомления!   \n8                Отличное приложение   \n9             Бесполезное приложение   \n10                       Все отлично   \n11                            Deniss   \n12             Отличная программа!!!   \n14                      Очень удобно   \n15                   Очень нравиться   \n16                Хорошее Приложение   \n17                            Super!   \n18                              Пау!   \n19                         Супер!!!!   \n20                 Достаточно удобно   \n21          Не регистрируется iPhone   \n22                            Ошибка   \n23                   Все понравилось   \n24                         Достойно!   \n25                           Отлично   \n26                Мобильный сбербанк   \n27  Наконец-то нормально заработало!   \n28                         Все гут;)   \n29                   Сбербанк онлайн   \n30                             Супер   \n\n                                               Review  Rating  \n0         Удобное приложение не глючит, нареканий нет       5  \n1                             Все устраивает, молодцы       5  \n2   Очень удобное приложение, стильное, создатели ...       5  \n3   Не получаеться перевести платежи,ничего не про...       1  \n4   На этой неделе начало жутко глючить приложение...       1  \n5                                   Приложение супер!       5  \n6   После последнего обновления невозможно перевес...       2  \n7   Неужели так трудно установить настройку уведом...       4  \n8   Удобное, интуитивно понятное меню приложения. ...       5  \n9   Для чего вообще сделали эту хрень? Приложение ...       1  \n10  Все отлично работает на 4 и 4s. Но функционал ...       5  \n11  Пока все устраивает.Очень удобное приложение. ...       5  \n12  Все в норме,куча приятных мелочей,действительн...       5  \n14                       Удобное, понятное приложение       5  \n15                           Очень удобное приложение       5  \n16  Все нравится, можно было бы расширить подробны...       4  \n17                Очень полезная программка!Нравится!       5  \n18                    Нормальное приложение, удобное)       5  \n19                          Очень удобное приложение?       5  \n20  Не прошло пару платежей после обновления , над...       4  \n21  Не могу зарегистрировать новое устройство (5S)...       1  \n22  При попытке перевода между своими счетами, всп...       3  \n23  Просто, удобно, красиво, спасибо за замечатель...       5  \n24  Все работает, не глючит и вызывает доверие. Сп...       5  \n25                 Очень удобное приложение. Спасибо.       5  \n26  Очень удобное приложение! Пользуюсь каждый ден...       5  \n27                    Всё летает на 5s, благодарочка!       5  \n28         Поскорее добавляйте новые фичи, вы крутые!       5  \n29  Очень хорошо сделано приложение, качественное ...       5  \n30  Мне данное приложение очень понравилось. Не ла...       5  \n"
     ]
    }
   ],
   "source": [
    "# real data test\n",
    "\n",
    "train_dataset = pd.read_csv(\"app_review_rating_train.csv\")\n",
    "test_dataset = pd.read_csv(\"app_review_rating_test.csv\")\n",
    "\n",
    "train_dataset[\"Reviews\"] = train_dataset[\"Title\"] + \" \" + train_dataset[\"Review\"]\n",
    "train_dataset = train_dataset.dropna()\n",
    "\n",
    "# oversampling\n",
    "df = train_dataset.loc[train_dataset['Rating'] == 1]\n",
    "df = pd.concat([df]*3)\n",
    "train_dataset = train_dataset.append(df)\n",
    "\n",
    "df = train_dataset.loc[train_dataset['Rating'] == 2]\n",
    "df = pd.concat([df]*5)\n",
    "train_dataset = train_dataset.append(df)\n",
    "\n",
    "df = train_dataset.loc[train_dataset['Rating'] == 3]\n",
    "df = pd.concat([df]*4)\n",
    "train_dataset = train_dataset.append(df)\n",
    "\n",
    "df = train_dataset.loc[train_dataset['Rating'] == 4]\n",
    "df = pd.concat([df]*2)\n",
    "train_dataset = train_dataset.append(df)\n",
    "\n",
    "test_dataset[\"Reviews\"] = test_dataset[\"Title\"] + \" \" + test_dataset[\"Review\"]\n",
    "test_dataset = test_dataset.dropna()\n",
    "\n",
    "train_reviews = np.array(train_dataset[\"Reviews\"])\n",
    "train_rating = np.array(train_dataset[\"Rating\"])\n",
    "test_reviews = np.array(test_dataset[\"Reviews\"])\n",
    "\n",
    "norm_train_reviews = normalize_corpus(train_reviews)\n",
    "norm_test_reviews = normalize_corpus(test_reviews)\n",
    "\n",
    "vectorizer, train_features = build_feature_matrix(documents=norm_train_reviews,\n",
    "                                                  feature_type='frequency',\n",
    "                                                  ngram_range=(1, 2), \n",
    "                                                  min_df=0.0, max_df=1.0)   \n",
    "\n",
    "\n",
    "lg.fit(train_features, train_rating)\n",
    "\n",
    "test_features = vectorizer.transform(norm_test_reviews)\n",
    "predicted_sentiment = nb.predict(test_features)\n",
    "\n",
    "test_dataset[\"Rating\"] = predicted_sentiment\n",
    "test_dataset = test_dataset.drop([\"Reviews\"], axis=1)\n",
    "\n",
    "print(test_dataset[\"Rating\"].value_counts().sort())\n",
    "\n",
    "\n",
    "test_dataset.to_csv(\"results.csv\", sep='\\t', encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'sort'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-e6296186addf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Rating\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   3079\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3080\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3081\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3083\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'sort'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(lg, open(\"lg_app_rating.pkl\", \"wb\"))\n",
    "pickle.dump(vectorizer, open(\"vectorizer.pkl\", \"wb\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
